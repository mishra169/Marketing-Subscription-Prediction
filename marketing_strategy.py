# -*- coding: utf-8 -*-
"""Marketing Strategy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gxkZ3ejXCxHqvVh_63Tt4Tv1LNOxN77f

**LIBRARY**
"""

# EDA Libraries
import matplotlib.pyplot as plt
import pandas as pd
import pickle
import seaborn as sns
from ipywidgets import Dropdown, interact, IntText
import plotly.express as px
import numpy as np
from datetime import datetime

# Machine Learning Libraries
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from ipywidgets import Dropdown, interact
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, RandomizedSearchCV
from sklearn.pipeline import make_pipeline
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, ConfusionMatrixDisplay, make_scorer, classification_report
from sklearn.tree import DecisionTreeClassifier
from imblearn.over_sampling import ADASYN, SMOTE
pd.set_option("display.max_columns", None)
from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder
from sklearn.feature_selection import SelectFromModel

"""**CLASS CREATION**"""

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
import seaborn as sns
from ipywidgets import Dropdown, interact

class Columnator:
    def __init__(self, df, target, df_test=False, labels=None):
       self.df = df
       self.df_test = df_test
       self.target = target
       self.labels = labels

    def comparator_categoric(self, column, normalize=False):
      df_columnator = self.df.groupby(column)[self.target].value_counts(normalize=normalize).to_frame().rename(columns={self.target: 'Number'}).reset_index()
      if self.labels != None:
            # Map the labels to the 'Survived' column
            df_columnator[self.target] = df_columnator[self.target].map(self.labels)
      # If normalize == True
      if normalize:
            df_columnator['Number'] = df_columnator['Number'] * 100
      plt.figure(figsize=(15,11))
      if self.df[column].nunique() < 7:
        ax = sns.barplot(y='Number', x=column, hue=self.target, data=df_columnator)
        for p in ax.patches:
          ax.annotate(format(p.get_height(), '.2f'),(p.get_x() + p.get_width() / 2, p.get_height()),ha='center', va='center', xytext=(0, 10), textcoords='offset points');
          if normalize:
            plt.yticks(range(0, 101, 10))
            plt.ylabel('Number [%]')
      else:
        ax = sns.barplot(x='Number', y=column, hue=self.target, data=df_columnator)
        for p in ax.patches:
          ax.annotate(format(p.get_width(), '.2f'),(p.get_width(), p.get_y() + p.get_height() / 2),xytext=(5, 0),textcoords='offset points',ha='left', va='center')
        if normalize:
          plt.xticks(range(0, 101, 10))
          plt.xlabel('Number [%]')
       # Set the figure title and legend title
      plt.title(f"{column} x {self.target}", fontsize=18)
      plt.legend(title=f"{self.target}")
        # Remove the top and right spines of the plot
      ax.spines['top'].set_visible(False)
      ax.spines['right'].set_visible(False)

    def dashbordator_categoric(self):
      panel1 = interact(
            self.comparator_categoric,
            column=Dropdown(options=self.df.dtypes[(self.df.dtypes == "object") | (self.df.dtypes == 'bool')].index)
        );
      return panel1;

    def comparator_numeric(self, column):
      survived_true = self.df[self.df[self.target] == True][column]
      survived_false = self.df[self.df[self.target] == False][column]
      fig = make_subplots()
      fig.add_trace(
            go.Histogram(x = survived_true, nbinsx=20)
        )
      fig.add_trace(
            go.Histogram(x = survived_false, nbinsx=20)
        )
      # Set the figure layout
      fig.update_layout(
            title_text=f"{column} x {self.target}"
        )
      # Set the x-axis label
      fig.update_xaxes(title_text=column)
      # Set the y-axis label
      fig.update_yaxes(title_text=f"Frequency", secondary_y=False)
      # Show the figure
      fig.show()

    def dashbordator_numeric(self):
        panel1 = interact(
            self.comparator_numeric,
            column=Dropdown(options= self.df.dtypes[(self.df.dtypes != 'object') & (self.df.dtypes != 'bool')].index)
        );
        return panel1;

df = pd.read_csv('/content/train.csv', sep=';')

"""Function Test"""

def columnator_frequency(column, boxplot = False, normalize = False):
    if df[column].dtype == 'object' or df[column].dtype == 'bool':
        df[column].value_counts(normalize = normalize).plot(kind= 'barh')
        plt.xlabel('Frequency')
        plt.ylabel(f'{column.capitalize()}');
    else:
        if boxplot == False:
            df[column].hist()
            plt.ylabel('Frequency')
            plt.xlabel(f'{column.capitalize()}');
        else:
            plt.boxplot(df[column])

    plt.title(f'{column.capitalize()} Frequency')

"""Analysis"""

df.info()

df.head()

df.shape

df.duplicated().sum()

df.dtypes

df.isna().sum()

df.describe().T

df[df['previous']==0].shape

"""**DATA CLEANING**"""

def balanceator(x):
    if x < 72:
        return 'Class E'
    elif x >= 72 and x < 448:
        return 'Class D'
    elif x >= 448 and x < 1428:
        return 'Class C'
    elif x >= 1428 and x < df['balance'].quantile(0.99):
        return 'Class B'
    else:
        return 'Class A'

def wrangle(path):
    df = pd.read_csv(path, sep=';')
    # Change object output to bool
    df['y'] = df['y'].apply(lambda x: True if x == 'yes' else False)
    df['default'] = df['default'].apply(lambda x: True if x == 'yes' else False)
    df['balance_class'] = df['balance'].apply(lambda x: balanceator(x))
    df['housing'] = df['housing'].apply(lambda x: True if x == 'yes' else False)
    df['loan'] = df['loan'].apply(lambda x: True if x == 'yes' else False)
    df['previous_bool'] = df['previous'].apply(lambda x: True if x != 0 else False)

    #dealing with outliers by capping them with 3 times std + mean.
    outliers = ['duration']
    upper_limit = df[outliers].mean() + 3*df[outliers].std()
    for i in upper_limit.index:
        df[i] = df[i].apply(lambda x: upper_limit.loc[i] if x > upper_limit.loc[i] else x)

    #drop columns:
    to_drop =['previous', 'day', 'poutcome', 'pdays']
    df.drop(columns= to_drop, inplace=True)


    return df

df_pos = wrangle('/content/train.csv')

"""Post Cleaning/Wrangle *Analysis*"""

df_pos.head()

df_pos.info()

df_pos.describe()

"""**MAIN ANALYSIS**"""

columnator_instansator = Columnator(df_pos, 'y')

def columnator_frequency2(column, boxplot = False, normalize = False):
    if df_pos[column].dtype == 'object' or df_pos[column].dtype == 'bool':
        df_pos[column].value_counts(normalize = normalize).plot(kind= 'barh')
        plt.xlabel('Frequency')
        plt.ylabel(f'{column.capitalize()}');
    else:
        if boxplot == False:
            df_pos[column].hist()
            plt.ylabel('Frequency')
            plt.xlabel(f'{column.capitalize()}');
        else:
            plt.boxplot(df_pos[column])

    plt.title(f'{column.capitalize()} Frequency')

mask_target_true = df_pos['y'] == True
def tabelator_crosstab(column):
   table = pd.crosstab(df_pos[mask_target_true]['balance_class'], df_pos[mask_target_true][column], normalize=True) * 100
   plt.figure(figsize= (20,12))
   sns.heatmap(table, annot=True, cmap='YlGnBu')

#checking data after wrangling
panel_columnator = interact(
    columnator_frequency2,
    column=Dropdown(options= df_pos.drop(columns='y')),
);

columnator_instansator.dashbordator_categoric()

columnator_instansator.dashbordator_numeric()

df_tabelator = df_pos[mask_target_true].drop(columns=['balance_class', 'y']).dtypes[(df_pos.dtypes == 'object') | (df_pos.dtypes == 'bool')].index

panel1 = interact(
    tabelator_crosstab,
    column = Dropdown(options= df_tabelator))

"""**DATA SPLITTING**"""

X = df_pos.drop(columns = ["y", "balance", 'duration'])
y = df_pos['y']

oe = OrdinalEncoder()
X = oe.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)

"""**DATA BALANCING**

Given the state of our data, we are applying SMOTE and ADASYN techniques to enhance model

*SMOTE:SMOTE is a technique to up-sample the minority classes while avoiding overfitting. It does this by generating new synthetic examples close to the other points (belonging to the minority class) in feature space*


"""

smote = SMOTE(random_state=42)

X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

print(f"""
Original X shape: {X_train.shape}
SMOTE X shape: {X_train_smote.shape}
""")

"""*ADASYN:ADASYN is based on the idea of adaptively generating minority data samples according to their distributions: more synthetic data is generated for minority class samples that are harder to learn compared to those minority samples that are easier to learn*"""

adasyn = ADASYN(random_state=42)

X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train, y_train)

print(f"""
Original X shape: {X_train.shape}
ADASYIN X shape: {X_train_adasyn.shape}
""")

"""BASELINE"""

acc_baseline = y_train.value_counts(normalize=True).max()
print("Baseline Accuracy:", round(acc_baseline*100, 2), "%")

"""**CLASS FOR RESULT ANALYSiS**"""

class Resultator():
  def __init__(self):
    self.data = pd.DataFrame(columns=['Model', 'Accuracy CV', 'Acc Std CV', 'Recall CV', 'Rec Std CV', 'Precision CV', 'Precision std CV' , 'Test Acc', 'Test Recall', 'Test Precision'])
  def add_results(self, X_test, y_test, model, model_name):
    results = {
            "Model": [],
            "Accuracy CV": [],
            "Acc Std CV": [],
            "Recall CV": [],
            "Rec Std CV": [],
            'Precision CV': [],
            "Precision std CV" : [],
            "Test Acc": [],
            "Test Recall": [],
            'Test Precision': []
        }
    cv_results = pd.DataFrame(model.cv_results_)
    results["Model"].append(model_name)
    results["Accuracy CV"].append(round(cv_results[cv_results["rank_test_recall"] == 1]["mean_test_accuracy"].iloc[0] * 100, 2))
    results["Acc Std CV"].append(round(cv_results[cv_results["rank_test_recall"] == 1]["std_test_accuracy"].iloc[0] * 100, 2))
    results["Recall CV"].append(round(cv_results[cv_results["rank_test_recall"] == 1]["mean_test_recall"].iloc[0] * 100, 2))
    results["Rec Std CV"].append(round(cv_results[cv_results["rank_test_recall"] == 1]["std_test_recall"].iloc[0] * 100, 2))
    results['Precision CV'].append(round(cv_results[cv_results['rank_test_recall'] ==1]['mean_test_precision'].iloc[0] * 100, 2))
    results['Precision std CV'].append(round(cv_results[cv_results['rank_test_recall'] ==1]['std_test_precision'].iloc[0] * 100, 2))

    results["Test Acc"].append(round(accuracy_score(y_test, model.predict(X_test)) * 100, 2))
    results["Test Recall"].append(round(recall_score(y_test, model.predict(X_test)) * 100, 2))
    results['Test Precision'].append(round(precision_score(y_test, model.predict(X_test)) * 100, 2))

    self.data = pd.concat([self.data, pd.DataFrame(results)])
    print(f"The Data from model {model_name} was acquired and stored.")
  def results(self):
     return self.data
  def plot_results(self, column):
    fig = px.bar(data_frame=self.data.sort_values("Test Recall", ascending=False).head(5),y="Model", x=f"{column}",
                 color= self.data.sort_values("Test Recall").head(5)["Model"],title=f"{column} comparison")
    fig.update_layout(yaxis={'categoryorder':'total descending'}, xaxis_title=f"{column}", yaxis_title="Models")
    fig.s
  def dashbordator(self):
    panel1 = interact(
            self.plot_results,
            column=Dropdown(options=self.data.drop(columns="Model").columns)
        );
    return panel1;

resultator = Resultator()

"""**MODEL**

the most important metric for this situation is recall. This is because we want the marketing team to target the clients with the highest likelihood of accepting the term deposit subscription, and recall measures the proportion of true positives (i.e., clients who would subscribe for the term deposit) among all actual positive cases (i.e., clients who were interested in subscribing). By optimizing for recall, we can ensure that the marketing team reaches out to as many interested clients as possible and maximizes the potential for subscription success.

*PARAMETERS*

*Decision Tree, Random Forest, KNN-Neighbour*
"""

params_dt = {
    "max_depth": [5, 10, 15, 20, 25, 30, None], # Maximum depth of the decision tree
    "criterion": ["gini","entropy"], # The quality criterion to measure the information gain when splitting nodes
    "min_samples_split": [2,3], # Minimum number of samples required to split an internal node
    "min_samples_leaf": [1,2] # Minimum number of samples required to be at a leaf node
}

params_rf = {
    "n_estimators": range(50,251,50), # Number of decision trees in the random forest
    "max_depth": range(5,31,5), # Maximum depth of the decision trees in the random forest
    "min_samples_split": [2,3], # Minimum number of samples required to split an internal node
    "min_samples_leaf": [1,2] # Minimum number of samples required to be at a leaf node
}

params_knn = {
    "n_neighbors": range(20, 151, 10), # Number of neighbors to consider for each data point
    "weights": ["uniform","distance"] # The weight function used in prediction (uniform weights or weights based on inverse distance)
}

"""*MODEL*"""

model_dt = RandomizedSearchCV(
    DecisionTreeClassifier(random_state=42), # Define the Decision Tree model
    params_dt, # Pass in the hyperparameters to be tuned from the dictionary we defined earlier
    n_jobs=-1, # Use all available CPU cores for parallel computation
    cv=10, # Set the number of folds for cross-validation
    n_iter= 10, # Set the number of iterations for randomized search
    scoring=["recall", "accuracy", 'precision'], # Set the evaluation metrics to be used for scoring
    refit="recall" # Choose the metric to optimize during randomized search
)

model_rf = RandomizedSearchCV(
    RandomForestClassifier(random_state=42), # Define the Random Forest model
    params_rf, # Pass in the hyperparameters to be tuned from the dictionary we defined earlier
    n_jobs=-1, # Use all available CPU cores for parallel computation
    cv=10, # Set the number of folds for cross-validation
    n_iter=35, # Set the number of iterations for randomized search
    scoring=["recall", "accuracy", 'precision'], # Set the evaluation metrics to be used for scoring
    refit="recall" # Choose the metric to optimize during randomized search
)

model_knn = GridSearchCV(
    KNeighborsClassifier(), # Define the KNN model
    params_knn, # Pass in the hyperparameters to be tuned from the dictionary we defined earlier
    n_jobs=-1, # Use all available CPU cores for parallel computation
    cv=10, # Set the number of folds for cross-validation
    scoring=["recall", "accuracy", 'precision'], # Set the evaluation metrics to be used for scoring
    refit="recall" # Choose the metric to optimize during randomized search
)

"""DECISION TREE"""

dt = GridSearchCV(DecisionTreeClassifier(random_state=42), {}, n_jobs=-1, cv=10, scoring=["recall", "accuracy", 'precision'], refit="recall")
dt.fit(X_train, y_train)

resultator.add_results(X_test, y_test, dt, "DecisionTreeBasic")

resultator.results()

ConfusionMatrixDisplay.from_estimator(dt,X_test,y_test)

# Extract importances from model
importances = dt.best_estimator_.feature_importances_
# Create a series with feature names and importances
feat_imp = pd.Series(importances)
# Plot 10 most important features
feat_imp.sort_values().tail(10).plot(kind="barh")
plt.xlabel("Feature Importance")
plt.ylabel("Feature")
plt.title("Feature Importance");

dt.best_estimator_.tree_.max_depth

"""With the information acquired we can conclude that:

The model accuracy is inferior to the baseline in both cross-validation and test scores.
The recall is bad and must be improved.
The max_depth of a single tree without any hyperparameters tuning is 37.
"age" column is by far the most "usefull" column, followed by 'job' and campaign.

**MODEL**

*WITH ORIGINAL DATA, HYPERPARAMETERIZATION*
"""

now = datetime.now()
model_dt.fit(X_train, y_train)
model_rf.fit(X_train, y_train)
model_knn.fit(X_train, y_train)
print(f"All the models fitted in: {datetime.now() - now} time")

resultator.add_results(X_test, y_test, model_dt, "DecisionTree")
resultator.add_results(X_test, y_test, model_rf, "RandomForest")
resultator.add_results(X_test, y_test, model_knn, "KNN")

resultator.results()

"""**MODEL**

*WITH SMOTE AND HYPERPARAMETERIZATION*
"""

now = datetime.now()
model_dt.fit(X_train_smote, y_train_smote)
model_rf.fit(X_train_smote, y_train_smote)
model_knn.fit(X_train_smote, y_train_smote)
print(f"All the models fitted in: {datetime.now() - now} time")

resultator.add_results(X_test, y_test, model_dt, "DecisionTreeSMOTE")
resultator.add_results(X_test, y_test, model_rf, "RandomForestSMOTE")
resultator.add_results(X_test, y_test, model_knn, "KNNSMOTE")

resultator.results()

"""**MODEL**

*WITH ADASYN AND HYPERPARAMETERIZATION*
"""

now = datetime.now()
model_dt.fit(X_train_adasyn, y_train_adasyn)
model_rf.fit(X_train_adasyn, y_train_adasyn)
model_knn.fit(X_train_adasyn, y_train_adasyn)
print(f"All the models fitted in: {datetime.now() - now} time")

resultator.add_results(X_test, y_test, model_dt, "DecisionTreeADASYN")
resultator.add_results(X_test, y_test, model_rf, "RandomForestADASYN")
resultator.add_results(X_test, y_test, model_knn, "KNNADASYN")

resultator.results().sort_values("Test Recall", ascending=False)

"""**RESULTS**

As we saw ADASYN produced the most accrate recall outputs among all models
"""

pd.DataFrame(model_knn.cv_results_).sort_values("rank_test_recall").head(3)

model_knn.best_params_

"""lower numbers means better the model have performed"""

recall_score(y_test, model_dt.predict(X_test))

ConfusionMatrixDisplay.from_estimator(model_knn, X_test,y_test)

"""As expected, since we were optimizing for high recall, we achieved the best performance for positive true cases, at the expense of accuracy due to the higher number of false positives. The confusion matrix provides a clear overview of the model's performance, with high true positive and false positive rates. Overall, the model's performance aligns with our objective of prioritizing the identification of true positive cases at the cost of an increased false positive rate.

**MODEL DEPLOYMENT**

refitting model
"""

X_adasyn, y_adasyn = adasyn.fit_resample(X, y)

model_knn = GridSearchCV(
    KNeighborsClassifier(weights="distance", n_neighbors= 20), # Define the KNN model
    {},
    # Pass in the hyperparameters to be tuned from the dictionary we defined earlier
    n_jobs=-1, # Use all available CPU cores for parallel computation
    cv=10, # Set the number of folds for cross-validation
    scoring=["recall", "accuracy"], # Set the evaluation metrics to be used for scoring
    refit="recall" # Choose the metric to optimize during randomized search
)

model_knn.fit(X_adasyn, y_adasyn)

pd.DataFrame(model_knn.cv_results_)

"""Dashboard"""

def make_prediction(age, job, marital, education, default, housing, loan,
                    contact, month,campaign, balance_class,
                    previous_bool):
    data = {
        "age": age,
        "job": job,
        "marital": marital,
        "education": education,
        "default": default,
        "housing": housing,
        "loan": loan,
        "contact": contact,
        "month": month,
        "campaign": campaign,
        "balance_class": balance_class,
        "previous_bool": previous_bool
    }
    df = pd.DataFrame(data, index=[0])
    prediction = model_knn.predict(oe.transform(df))[0]
    if prediction == 0:
        return "Probably will not convert into a client"
    else:
        return "Probably will convert into a client"

print("Will subscribe for a term deposit?")
s1 = interact(
    make_prediction,
    age=IntText(),

    job=Dropdown(
        options= df_pos["job"].unique()
    ),
    marital=Dropdown(
        options= df_pos["marital"].unique()
    ),
    education=Dropdown(
        options= df_pos["education"].unique()
    ),
    default=Dropdown(
        options= df_pos["default"].unique()
    ),
    housing=Dropdown(
        options= df_pos["housing"].unique()
    ),
    loan=Dropdown(
        options= df_pos["loan"].unique()
    ),
    contact=Dropdown(
        options= df_pos["contact"].unique()
    ),
    month=Dropdown(
        options= df_pos["month"].unique()
     ),
    campaign=IntText(),
    balance_class=Dropdown(
        options= df_pos["balance_class"].unique()
    ),
    previous_bool=Dropdown(
        options= df_pos["previous_bool"].unique()
    )
);